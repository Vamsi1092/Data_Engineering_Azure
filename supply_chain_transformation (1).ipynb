{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f38edf34-3992-4cd0-a06f-4cfc74dc403f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mExecutionError\u001B[0m                            Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2889180384597416>, line 7\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m configs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.account.auth.type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOAuth\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.account.oauth.provider.type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124morg.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m      3\u001B[0m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.account.oauth2.client.id\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1b54d5ce-216f-4a34-90c2-ef7f8b6c12b6\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m      4\u001B[0m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.account.oauth2.client.secret\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcgy8Q~31Pbq03Yatjuy8ybX5RBN_WfcGQwKAecp0\u001B[39m\u001B[38;5;124m'\u001B[39m,\n",
       "\u001B[1;32m      5\u001B[0m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.account.oauth2.client.endpoint\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://login.microsoftonline.com/33f660a6-def3-41fe-aeb3-be31f445bece/oauth2/token\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n",
       "\u001B[0;32m----> 7\u001B[0m dbutils\u001B[38;5;241m.\u001B[39mfs\u001B[38;5;241m.\u001B[39mmount(\n",
       "\u001B[1;32m      8\u001B[0m source \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mabfss://supply-chain-dataset@vamsisupplychain.dfs.core.windows.net\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;66;03m# contrainer@storageacc\u001B[39;00m\n",
       "\u001B[1;32m      9\u001B[0m mount_point \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/mnt/supplychain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m     10\u001B[0m extra_configs \u001B[38;5;241m=\u001B[39m configs)\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/dbruntime/dbutils.py:161\u001B[0m, in \u001B[0;36mprettify_exception_message.<locals>.f_with_exception_handling\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    159\u001B[0m exc\u001B[38;5;241m.\u001B[39m__context__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    160\u001B[0m exc\u001B[38;5;241m.\u001B[39m__cause__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[0;32m--> 161\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
       "\n",
       "\u001B[0;31mExecutionError\u001B[0m: An error occurred while calling o2439.mount.\n",
       ": java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/supplychain; nested exception is: \n",
       "\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/supplychain\n",
       "\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:148)\n",
       "\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:70)\n",
       "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:1145)\n",
       "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.$anonfun$mount$1(DBUtilsCore.scala:1171)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:74)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:74)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:74)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:74)\n",
       "\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:139)\n",
       "\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:1165)\n",
       "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
       "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:306)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
       "Caused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/supplychain\n",
       "\tat scala.Predef$.require(Predef.scala:281)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:800)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$2(MetadataManager.scala:1182)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:955)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:1171)\n",
       "\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:808)\n",
       "\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:128)\n",
       "\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n",
       "\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n",
       "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
       "\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n",
       "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.$anonfun$applyOrElse$10(DbfsServerBackend.scala:451)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:451)\n",
       "\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:344)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1032)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:952)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:552)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:521)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$8(ActivityContextFactory.scala:681)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:681)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:652)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:634)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:253)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:521)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:411)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:110)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:110)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:126)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:123)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:92)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.lang.Thread.run(Thread.java:840)\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ExecutionError",
        "evalue": "An error occurred while calling o2439.mount.\n: java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/supplychain; nested exception is: \n\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/supplychain\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:148)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:70)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:1145)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.$anonfun$mount$1(DBUtilsCore.scala:1171)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:74)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:74)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:74)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:74)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:139)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:1165)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\nCaused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/supplychain\n\tat scala.Predef$.require(Predef.scala:281)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:800)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$2(MetadataManager.scala:1182)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:955)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:1171)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:808)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:128)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n\tat scala.collection.immutable.List.foreach(List.scala:431)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.$anonfun$applyOrElse$10(DbfsServerBackend.scala:451)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:451)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:344)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1032)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:952)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:552)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:521)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$8(ActivityContextFactory.scala:681)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:681)\n\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:652)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:634)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:253)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:521)\n\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:411)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:110)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:110)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:126)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:123)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:92)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n\tat java.lang.Thread.run(Thread.java:840)\n"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>ExecutionError</span>: An error occurred while calling o2439.mount.\n: java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/supplychain; nested exception is: \n\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/supplychain\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:148)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:70)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:1145)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.$anonfun$mount$1(DBUtilsCore.scala:1171)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:74)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:74)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:74)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:74)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:139)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:1165)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\nCaused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/supplychain\n\tat scala.Predef$.require(Predef.scala:281)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:800)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$2(MetadataManager.scala:1182)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:955)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:1171)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:808)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:128)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n\tat scala.collection.immutable.List.foreach(List.scala:431)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.$anonfun$applyOrElse$10(DbfsServerBackend.scala:451)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:451)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:344)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1032)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:952)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:552)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:521)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$8(ActivityContextFactory.scala:681)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:681)\n\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:652)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:634)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:253)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:521)\n\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:411)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:110)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:110)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:126)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:123)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:92)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n\tat java.lang.Thread.run(Thread.java:840)\n"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mExecutionError\u001B[0m                            Traceback (most recent call last)",
        "File \u001B[0;32m<command-2889180384597416>, line 7\u001B[0m\n\u001B[1;32m      1\u001B[0m configs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.account.auth.type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOAuth\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      2\u001B[0m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.account.oauth.provider.type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124morg.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.account.oauth2.client.id\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1b54d5ce-216f-4a34-90c2-ef7f8b6c12b6\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.account.oauth2.client.secret\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcgy8Q~31Pbq03Yatjuy8ybX5RBN_WfcGQwKAecp0\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.account.oauth2.client.endpoint\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://login.microsoftonline.com/33f660a6-def3-41fe-aeb3-be31f445bece/oauth2/token\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[0;32m----> 7\u001B[0m dbutils\u001B[38;5;241m.\u001B[39mfs\u001B[38;5;241m.\u001B[39mmount(\n\u001B[1;32m      8\u001B[0m source \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mabfss://supply-chain-dataset@vamsisupplychain.dfs.core.windows.net\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;66;03m# contrainer@storageacc\u001B[39;00m\n\u001B[1;32m      9\u001B[0m mount_point \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/mnt/supplychain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     10\u001B[0m extra_configs \u001B[38;5;241m=\u001B[39m configs)\n",
        "File \u001B[0;32m/databricks/python_shell/dbruntime/dbutils.py:161\u001B[0m, in \u001B[0;36mprettify_exception_message.<locals>.f_with_exception_handling\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    159\u001B[0m exc\u001B[38;5;241m.\u001B[39m__context__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    160\u001B[0m exc\u001B[38;5;241m.\u001B[39m__cause__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 161\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
        "\u001B[0;31mExecutionError\u001B[0m: An error occurred while calling o2439.mount.\n: java.rmi.RemoteException: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/supplychain; nested exception is: \n\tjava.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/supplychain\n\tat com.databricks.backend.daemon.data.client.DbfsClient.send0(DbfsClient.scala:148)\n\tat com.databricks.backend.daemon.data.client.DbfsClient.sendIdempotent(DbfsClient.scala:70)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.createOrUpdateMount(DBUtilsCore.scala:1145)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.$anonfun$mount$1(DBUtilsCore.scala:1171)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:507)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:611)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:631)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionContext(DBUtilsCore.scala:74)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.withAttributionTags(DBUtilsCore.scala:74)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:606)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:516)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperationWithResultTags(DBUtilsCore.scala:74)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:508)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:476)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordOperation(DBUtilsCore.scala:74)\n\tat com.databricks.backend.daemon.dbutils.FSUtils.recordDbutilsFsOp(DBUtilsCore.scala:139)\n\tat com.databricks.backend.daemon.dbutils.DBUtilsCore.mount(DBUtilsCore.scala:1165)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:119)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\nCaused by: java.lang.IllegalArgumentException: requirement failed: Directory already mounted: /mnt/supplychain\n\tat scala.Predef$.require(Predef.scala:281)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$insertMount$1(MetadataManager.scala:800)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.$anonfun$modifyAndVerify$2(MetadataManager.scala:1182)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.withRetries(MetadataManager.scala:955)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.modifyAndVerify(MetadataManager.scala:1171)\n\tat com.databricks.backend.daemon.data.server.DefaultMetadataManager.insertMount(MetadataManager.scala:808)\n\tat com.databricks.backend.daemon.data.server.handler.MountHandler.receive(MountHandler.scala:128)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1(SessionContext.scala:54)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.$anonfun$queryHandlers$1$adapted(SessionContext.scala:53)\n\tat scala.collection.immutable.List.foreach(List.scala:431)\n\tat com.databricks.backend.daemon.data.server.session.SessionContext.queryHandlers(SessionContext.scala:53)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.$anonfun$applyOrElse$10(DbfsServerBackend.scala:451)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:451)\n\tat com.databricks.backend.daemon.data.server.DbfsServerBackend$$anonfun$receive$4.applyOrElse(DbfsServerBackend.scala:344)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:508)\n\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:613)\n\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:636)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:608)\n\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:517)\n\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:509)\n\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1032)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:952)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:552)\n\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:521)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$8(ActivityContextFactory.scala:681)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:47)\n\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:681)\n\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:652)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:634)\n\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:253)\n\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:521)\n\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:411)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:110)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:271)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:267)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:110)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:126)\n\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:123)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:92)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n\tat java.lang.Thread.run(Thread.java:840)\n"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n",
    "\"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "\"fs.azure.account.oauth2.client.id\": \"1b54d5ce-216f-4a34-90c2-ef7f8b6c12b6\",\n",
    "\"fs.azure.account.oauth2.client.secret\": 'cgy8Q~31Pbq03Yatjuy8ybX5RBN_WfcGQwKAecp0',\n",
    "\"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/33f660a6-def3-41fe-aeb3-be31f445bece/oauth2/token\"}\n",
    "\n",
    "dbutils.fs.mount(\n",
    "source = \"abfss://supply-chain-dataset@vamsisupplychain.dfs.core.windows.net\", # contrainer@storageacc\n",
    "mount_point = \"/mnt/supplychain\",\n",
    "extra_configs = configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "965a2f7e-9c7d-41cf-a2ff-31aeff6624ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/mnt/supplychain/raw-data/</td><td>raw-data/</td><td>0</td><td>1731866424000</td></tr><tr><td>dbfs:/mnt/supplychain/transformed-data/</td><td>transformed-data/</td><td>0</td><td>1731866438000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/mnt/supplychain/raw-data/",
         "raw-data/",
         0,
         1731866424000
        ],
        [
         "dbfs:/mnt/supplychain/transformed-data/",
         "transformed-data/",
         0,
         1731866438000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs\n",
    "ls \"mnt/supplychain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "724879ba-b3c2-484e-9834-3913251b24c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=1935808076209434#setting/sparkui/1120-035144-qnspif1l/driver-4440008164143958149\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*, 4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f4a5c6e3860>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f120a86-3973-48a1-a403-8d03b783ebf3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"/mnt/supplychain/raw-data/SCdataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f4ba0f4-ba4c-4bd8-9b73-3a9fde6fa044",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import round, sum, corr, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75b33166-f139-441e-a9d9-f01251f5cf26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+------------------+------------+-----------------------+------------------+---------------------+------------+----------+----------------+--------------+-----------------+------------------+-------------+---------+---------+------------------+-----------------------+-------------------+------------------+-------------------+--------------------+-------+------------------+\n|Product type|  SKU|             Price|Availability|Number of products sold| Revenue generated|Customer demographics|Stock levels|Lead times|Order quantities|Shipping times|Shipping carriers|    Shipping costs|Supplier name| Location|Lead time|Production volumes|Manufacturing lead time|Manufacturing costs|Inspection results|       Defect rates|Transportation modes| Routes|             Costs|\n+------------+-----+------------------+------------+-----------------------+------------------+---------------------+------------+----------+----------------+--------------+-----------------+------------------+-------------+---------+---------+------------------+-----------------------+-------------------+------------------+-------------------+--------------------+-------+------------------+\n|    haircare| SKU0| 69.80800554211577|          55|                    802| 8661.996792392383|           Non-binary|          58|         7|              96|             4|        Carrier B| 2.956572139430807|   Supplier 3|   Mumbai|       29|               215|                     29|  46.27987924050832|           Pending|0.22641036084992516|                Road|Route B|187.75207545920392|\n|    skincare| SKU1|14.843523275084339|          95|                    736| 7460.900065445849|               Female|          53|        30|              37|             2|        Carrier A|  9.71657477143131|   Supplier 3|   Mumbai|       23|               517|                     30|     33.61676895373|           Pending|  4.854068026388706|                Road|Route B| 503.0655791496692|\n|    haircare| SKU2|11.319683293090566|          34|                      8|  9577.74962586873|              Unknown|           1|        10|              88|             2|        Carrier B| 8.054479261732155|   Supplier 1|   Mumbai|       12|               971|                     27| 30.688019348284204|           Pending|  4.580592619199229|                 Air|Route C|141.92028177151906|\n|    skincare| SKU3|61.163343016437736|          68|                     83| 7766.836425685233|           Non-binary|          23|        13|              59|             6|        Carrier C|1.7295685635434288|   Supplier 5|  Kolkata|       24|               937|                     18|  35.62474139712503|              Fail|   4.74664862064775|                Rail|Route A|254.77615921928663|\n|    skincare| SKU4| 4.805496036345893|          26|                    871| 2686.505151567447|           Non-binary|           5|         3|              56|             8|        Carrier A|3.8905479158706715|   Supplier 1|    Delhi|        5|               414|                      3|  92.06516059871285|              Fail|  3.145579522833002|                 Air|Route A| 923.4406317119222|\n|    haircare| SKU5|1.6999760138659377|          87|                    147| 2828.348745975759|           Non-binary|          90|        27|              66|             3|        Carrier B| 4.444098864382293|   Supplier 4|Bangalore|       10|               104|                     17|   56.7664755574318|              Fail| 2.7791935115711617|                Road|Route A| 235.4612367355375|\n|    skincare| SKU6| 4.078332863107945|          48|                     65| 7823.476559531737|                 Male|          11|        15|              58|             8|        Carrier C|3.8807633029520034|   Supplier 3|  Kolkata|       14|               314|                     24| 1.0850685695870688|           Pending| 1.0009106193041357|                 Sea|Route A|134.36909686103172|\n|   cosmetics| SKU7| 42.95838438246007|          59|                    426| 8496.103813089838|               Female|          93|        17|              11|             1|        Carrier B|2.3483387844177805|   Supplier 4|Bangalore|       22|               564|                      1|  99.46610860359912|              Fail| 0.3981771868506506|                Road|Route C| 802.0563118175586|\n|   cosmetics| SKU8| 68.71759674852733|          78|                    150| 7517.363210631127|               Female|           5|        10|              15|             7|        Carrier C|3.4047338570830266|   Supplier 4|   Mumbai|       13|               769|                      8| 11.423027139565695|           Pending| 2.7098626911099615|                 Sea|Route B|505.55713422546415|\n|    skincare| SKU9| 64.01573294127854|          35|                    980| 4971.145987585558|              Unknown|          14|        27|              83|             1|        Carrier A| 7.166645291048216|   Supplier 2|  Chennai|       29|               963|                     23|  47.95760163495158|           Pending|  3.844614478767585|                Rail|Route B| 995.9294614986417|\n|    skincare|SKU10|15.707795681912138|          11|                    996| 2330.965802091949|           Non-binary|          51|        13|              80|             2|        Carrier C| 8.673211211278613|   Supplier 5|  Kolkata|       18|               830|                      5|  96.52735278531091|              Pass| 1.7273139283559424|                Road|Route B|  806.103177702923|\n|    skincare|SKU11| 90.63545998228867|          95|                    960| 6099.944115581452|               Female|          46|        23|              60|             1|        Carrier A| 4.523943124316663|   Supplier 2|  Kolkata|       28|               362|                     11| 27.592363086663696|           Pending|0.02116982137299439|                 Air|Route A|126.72303340940725|\n|    haircare|SKU12| 71.21338907536008|          41|                    336|2873.7414460214413|              Unknown|         100|        30|              85|             4|        Carrier A| 1.325274010184522|   Supplier 4|  Kolkata|        3|               563|                      3|  32.32128621342403|              Fail| 2.1612537475559117|                Road|Route B| 402.9687890737706|\n|    skincare|SKU13|16.160393317379977|           5|                    249|4052.7384162378667|                 Male|          80|         8|              48|             9|        Carrier A| 9.537283061108338|   Supplier 5|Bangalore|       23|               173|                     10|  97.82905011017327|           Pending| 1.6310742300715386|                Road|Route B| 547.2410051609685|\n|    skincare|SKU14| 99.17132863862419|          26|                    562| 8653.570926469802|           Non-binary|          54|        29|              78|             5|        Carrier B|2.0397701894493316|   Supplier 1|  Kolkata|       25|               558|                     14|  5.791436629862989|           Pending|0.10068285156509371|                 Air|Route B| 929.2352899608896|\n|    skincare|SKU15| 36.98924492862691|          94|                    469| 5442.086785397673|           Non-binary|           9|         8|              69|             7|        Carrier B|2.4220397232752044|   Supplier 1|Bangalore|       14|               580|                      7|  97.12128175147431|              Pass|  2.264405761198549|                 Sea|Route B|127.86180000162541|\n|    skincare|SKU16| 7.547172109791272|          74|                    280| 6453.797968176285|               Female|           2|         5|              78|             1|        Carrier B| 4.191324585705502|   Supplier 1|Bangalore|        3|               399|                     21|  77.10634249785001|              Pass|  1.012563089258049|                 Air|Route A| 865.5257797712403|\n|   cosmetics|SKU17| 81.46253436923702|          82|                    126| 2629.396434845262|               Female|          45|        17|              85|             9|        Carrier C| 3.585418958232342|   Supplier 1|  Chennai|        7|               453|                     16| 47.679680368355335|              Fail|0.10202075491817619|                 Air|Route C| 670.9343907924103|\n|    haircare|SKU18|36.443627770460935|          23|                    620| 9364.673505076173|              Unknown|          10|        10|              46|             8|        Carrier C| 4.339224714110709|   Supplier 2|  Kolkata|       18|               374|                     17|  27.10798085484392|           Pending| 2.2319391107292637|                 Sea|Route A| 593.4802587206518|\n|    skincare|SKU19| 51.12387008796474|         100|                    187| 2553.495584991215|              Unknown|          48|        11|              94|             3|        Carrier A| 4.742635882841877|   Supplier 4|  Chennai|       20|               694|                     16|  82.37332058799021|              Fail| 3.6464508654170293|                Road|Route C|477.30763109090344|\n+------------+-----+------------------+------------+-----------------------+------------------+---------------------+------------+----------+----------------+--------------+-----------------+------------------+-------------+---------+---------+------------------+-----------------------+-------------------+------------------+-------------------+--------------------+-------+------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f6c051f-788c-4587-8628-7b31d01eb4e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+------------------+------------+-----------------------+------------------+---------------------+------------+----------+----------------+--------------+-----------------+------------------+-------------+---------+---------+------------------+-----------------------+-------------------+------------------+-------------------+--------------------+-------+------------------+\n|product_type|  sku|             price|availability|number_of_products_sold| revenue_generated|customer_demographics|stock_levels|lead_times|order_quantities|shipping_times|shipping_carriers|    shipping_costs|supplier_name| location|lead_time|production_volumes|manufacturing_lead_time|manufacturing_costs|inspection_results|       defect_rates|transportation_modes| routes|             costs|\n+------------+-----+------------------+------------+-----------------------+------------------+---------------------+------------+----------+----------------+--------------+-----------------+------------------+-------------+---------+---------+------------------+-----------------------+-------------------+------------------+-------------------+--------------------+-------+------------------+\n|    haircare| SKU0| 69.80800554211577|          55|                    802| 8661.996792392383|           Non-binary|          58|         7|              96|             4|        Carrier B| 2.956572139430807|   Supplier 3|   Mumbai|       29|               215|                     29|  46.27987924050832|           Pending|0.22641036084992516|                Road|Route B|187.75207545920392|\n|    skincare| SKU1|14.843523275084339|          95|                    736| 7460.900065445849|               Female|          53|        30|              37|             2|        Carrier A|  9.71657477143131|   Supplier 3|   Mumbai|       23|               517|                     30|     33.61676895373|           Pending|  4.854068026388706|                Road|Route B| 503.0655791496692|\n|    haircare| SKU2|11.319683293090566|          34|                      8|  9577.74962586873|              Unknown|           1|        10|              88|             2|        Carrier B| 8.054479261732155|   Supplier 1|   Mumbai|       12|               971|                     27| 30.688019348284204|           Pending|  4.580592619199229|                 Air|Route C|141.92028177151906|\n|    skincare| SKU3|61.163343016437736|          68|                     83| 7766.836425685233|           Non-binary|          23|        13|              59|             6|        Carrier C|1.7295685635434288|   Supplier 5|  Kolkata|       24|               937|                     18|  35.62474139712503|              Fail|   4.74664862064775|                Rail|Route A|254.77615921928663|\n|    skincare| SKU4| 4.805496036345893|          26|                    871| 2686.505151567447|           Non-binary|           5|         3|              56|             8|        Carrier A|3.8905479158706715|   Supplier 1|    Delhi|        5|               414|                      3|  92.06516059871285|              Fail|  3.145579522833002|                 Air|Route A| 923.4406317119222|\n|    haircare| SKU5|1.6999760138659377|          87|                    147| 2828.348745975759|           Non-binary|          90|        27|              66|             3|        Carrier B| 4.444098864382293|   Supplier 4|Bangalore|       10|               104|                     17|   56.7664755574318|              Fail| 2.7791935115711617|                Road|Route A| 235.4612367355375|\n|    skincare| SKU6| 4.078332863107945|          48|                     65| 7823.476559531737|                 Male|          11|        15|              58|             8|        Carrier C|3.8807633029520034|   Supplier 3|  Kolkata|       14|               314|                     24| 1.0850685695870688|           Pending| 1.0009106193041357|                 Sea|Route A|134.36909686103172|\n|   cosmetics| SKU7| 42.95838438246007|          59|                    426| 8496.103813089838|               Female|          93|        17|              11|             1|        Carrier B|2.3483387844177805|   Supplier 4|Bangalore|       22|               564|                      1|  99.46610860359912|              Fail| 0.3981771868506506|                Road|Route C| 802.0563118175586|\n|   cosmetics| SKU8| 68.71759674852733|          78|                    150| 7517.363210631127|               Female|           5|        10|              15|             7|        Carrier C|3.4047338570830266|   Supplier 4|   Mumbai|       13|               769|                      8| 11.423027139565695|           Pending| 2.7098626911099615|                 Sea|Route B|505.55713422546415|\n|    skincare| SKU9| 64.01573294127854|          35|                    980| 4971.145987585558|              Unknown|          14|        27|              83|             1|        Carrier A| 7.166645291048216|   Supplier 2|  Chennai|       29|               963|                     23|  47.95760163495158|           Pending|  3.844614478767585|                Rail|Route B| 995.9294614986417|\n|    skincare|SKU10|15.707795681912138|          11|                    996| 2330.965802091949|           Non-binary|          51|        13|              80|             2|        Carrier C| 8.673211211278613|   Supplier 5|  Kolkata|       18|               830|                      5|  96.52735278531091|              Pass| 1.7273139283559424|                Road|Route B|  806.103177702923|\n|    skincare|SKU11| 90.63545998228867|          95|                    960| 6099.944115581452|               Female|          46|        23|              60|             1|        Carrier A| 4.523943124316663|   Supplier 2|  Kolkata|       28|               362|                     11| 27.592363086663696|           Pending|0.02116982137299439|                 Air|Route A|126.72303340940725|\n|    haircare|SKU12| 71.21338907536008|          41|                    336|2873.7414460214413|              Unknown|         100|        30|              85|             4|        Carrier A| 1.325274010184522|   Supplier 4|  Kolkata|        3|               563|                      3|  32.32128621342403|              Fail| 2.1612537475559117|                Road|Route B| 402.9687890737706|\n|    skincare|SKU13|16.160393317379977|           5|                    249|4052.7384162378667|                 Male|          80|         8|              48|             9|        Carrier A| 9.537283061108338|   Supplier 5|Bangalore|       23|               173|                     10|  97.82905011017327|           Pending| 1.6310742300715386|                Road|Route B| 547.2410051609685|\n|    skincare|SKU14| 99.17132863862419|          26|                    562| 8653.570926469802|           Non-binary|          54|        29|              78|             5|        Carrier B|2.0397701894493316|   Supplier 1|  Kolkata|       25|               558|                     14|  5.791436629862989|           Pending|0.10068285156509371|                 Air|Route B| 929.2352899608896|\n|    skincare|SKU15| 36.98924492862691|          94|                    469| 5442.086785397673|           Non-binary|           9|         8|              69|             7|        Carrier B|2.4220397232752044|   Supplier 1|Bangalore|       14|               580|                      7|  97.12128175147431|              Pass|  2.264405761198549|                 Sea|Route B|127.86180000162541|\n|    skincare|SKU16| 7.547172109791272|          74|                    280| 6453.797968176285|               Female|           2|         5|              78|             1|        Carrier B| 4.191324585705502|   Supplier 1|Bangalore|        3|               399|                     21|  77.10634249785001|              Pass|  1.012563089258049|                 Air|Route A| 865.5257797712403|\n|   cosmetics|SKU17| 81.46253436923702|          82|                    126| 2629.396434845262|               Female|          45|        17|              85|             9|        Carrier C| 3.585418958232342|   Supplier 1|  Chennai|        7|               453|                     16| 47.679680368355335|              Fail|0.10202075491817619|                 Air|Route C| 670.9343907924103|\n|    haircare|SKU18|36.443627770460935|          23|                    620| 9364.673505076173|              Unknown|          10|        10|              46|             8|        Carrier C| 4.339224714110709|   Supplier 2|  Kolkata|       18|               374|                     17|  27.10798085484392|           Pending| 2.2319391107292637|                 Sea|Route A| 593.4802587206518|\n|    skincare|SKU19| 51.12387008796474|         100|                    187| 2553.495584991215|              Unknown|          48|        11|              94|             3|        Carrier A| 4.742635882841877|   Supplier 4|  Chennai|       20|               694|                     16|  82.37332058799021|              Fail| 3.6464508654170293|                Road|Route C|477.30763109090344|\n+------------+-----+------------------+------------+-----------------------+------------------+---------------------+------------+----------+----------------+--------------+-----------------+------------------+-------------+---------+---------+------------------+-----------------------+-------------------+------------------+-------------------+--------------------+-------+------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_renamed = dataset.toDF(*[col.replace(\" \",\"_\").lower() for col in dataset.columns])\n",
    "df_renamed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a2166b5-4bd3-4173-ab44-ca23afe34708",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+-----+------------+-----------------------+-----------------+---------------------+------------+----------+----------------+--------------+-----------------+--------------+-------------+--------+---------+------------------+-----------------------+-------------------+------------------+------------+--------------------+------+-----+\n|product_type|sku|price|availability|number_of_products_sold|revenue_generated|customer_demographics|stock_levels|lead_times|order_quantities|shipping_times|shipping_carriers|shipping_costs|supplier_name|location|lead_time|production_volumes|manufacturing_lead_time|manufacturing_costs|inspection_results|defect_rates|transportation_modes|routes|costs|\n+------------+---+-----+------------+-----------------------+-----------------+---------------------+------------+----------+----------------+--------------+-----------------+--------------+-------------+--------+---------+------------------+-----------------------+-------------------+------------------+------------+--------------------+------+-----+\n|           0|  0|    0|           0|                      0|                0|                    0|           0|         0|               0|             0|                0|             0|            0|       0|        0|                 0|                      0|                  0|                 0|           0|                   0|     0|    0|\n+------------+---+-----+------------+-----------------------+-----------------+---------------------+------------+----------+----------------+--------------+-----------------+--------------+-------------+--------+---------+------------------+-----------------------+-------------------+------------------+------------+--------------------+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# checking for null values\n",
    "null_counts = df_renamed.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df_renamed.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd4df12d-83f3-4444-bc50-204313484500",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-----+------------------+-----------------+-----------------------+-----------------+---------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+-------------+---------+----------------+------------------+-----------------------+-------------------+------------------+------------------+--------------------+-------+------------------+\n|summary|product_type|  sku|             price|     availability|number_of_products_sold|revenue_generated|customer_demographics|      stock_levels|       lead_times| order_quantities|    shipping_times|shipping_carriers|    shipping_costs|supplier_name| location|       lead_time|production_volumes|manufacturing_lead_time|manufacturing_costs|inspection_results|      defect_rates|transportation_modes| routes|             costs|\n+-------+------------+-----+------------------+-----------------+-----------------------+-----------------+---------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+-------------+---------+----------------+------------------+-----------------------+-------------------+------------------+------------------+--------------------+-------+------------------+\n|  count|         100|  100|               100|              100|                    100|              100|                  100|               100|              100|              100|               100|              100|               100|          100|      100|             100|               100|                    100|                100|               100|               100|                 100|    100|               100|\n|   mean|        NULL| NULL| 49.46246134464368|             48.4|                 460.99|5776.048187380086|                 NULL|             47.77|            15.96|            49.22|              5.75|             NULL| 5.548149072019587|         NULL|     NULL|           17.08|            567.84|                  14.77|  47.26669324146991|              NULL| 2.277157992739611|                NULL|   NULL|  529.245782158141|\n| stddev|        NULL| NULL|31.168192736588534|30.74331659322909|       303.780073790766|2732.841744313675|                 NULL|31.369371602687146|8.785801217322359|26.78442936793048|2.7242828729258592|             NULL|2.6513755242811476|         NULL|     NULL|8.84625127475823| 263.0468606714228|      8.912430316216453| 28.982841217606083|              NULL|1.4613655489431403|                NULL|   NULL|258.30169620786694|\n|    min|   cosmetics| SKU0|1.6999760138659377|                1|                      8|1061.618523013288|               Female|                 0|                1|                1|                 1|        Carrier A|1.0134865660958963|   Supplier 1|Bangalore|               1|               104|                      1| 1.0850685695870688|              Fail|0.0186075676310149|                 Air|Route A|103.91624796070495|\n|    max|    skincare|SKU99| 99.17132863862419|              100|                    996|9866.465457979697|              Unknown|               100|               30|               96|                10|        Carrier C| 9.929816245277259|   Supplier 5|   Mumbai|              30|               985|                     30|  99.46610860359912|           Pending| 4.939255288620948|                 Sea|Route C| 997.4134501331946|\n+-------+------------+-----+------------------+-----------------+-----------------------+-----------------+---------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+-------------+---------+----------------+------------------+-----------------------+-------------------+------------------+------------------+--------------------+-------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_renamed.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a03c7674-358b-435e-9edb-8345901edcb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- product_type: string (nullable = true)\n |-- sku: string (nullable = true)\n |-- price: double (nullable = true)\n |-- availability: integer (nullable = true)\n |-- number_of_products_sold: integer (nullable = true)\n |-- revenue_generated: double (nullable = true)\n |-- customer_demographics: string (nullable = true)\n |-- stock_levels: integer (nullable = true)\n |-- lead_times: integer (nullable = true)\n |-- order_quantities: integer (nullable = true)\n |-- shipping_times: integer (nullable = true)\n |-- shipping_carriers: string (nullable = true)\n |-- shipping_costs: double (nullable = true)\n |-- supplier_name: string (nullable = true)\n |-- location: string (nullable = true)\n |-- lead_time: integer (nullable = true)\n |-- production_volumes: integer (nullable = true)\n |-- manufacturing_lead_time: integer (nullable = true)\n |-- manufacturing_costs: double (nullable = true)\n |-- inspection_results: string (nullable = true)\n |-- defect_rates: double (nullable = true)\n |-- transportation_modes: string (nullable = true)\n |-- routes: string (nullable = true)\n |-- costs: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df_renamed.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac626403-644b-46c0-9394-7c5d7c853469",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sales Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8e72e43-dbc2-4093-99f0-e453f68236ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+-------------------+-------------+\n|product_type|total_revenue|total_products_sold|average_price|\n+------------+-------------+-------------------+-------------+\n|    skincare|    241628.16|              20731|        47.26|\n|    haircare|    174455.39|              13611|        46.01|\n|   cosmetics|    161521.27|              11757|        57.36|\n+------------+-------------+-------------------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Identifying the top selling Product type on Revenue\n",
    "\n",
    "df_renamed.createOrReplaceTempView(\"df_renamed\")\n",
    "top_revenue = spark.sql(\"\"\"\n",
    "                        select \n",
    "                        product_type,\n",
    "                        round(sum(revenue_generated),2) as total_revenue,\n",
    "                        sum(number_of_products_sold) as total_products_sold,\n",
    "                        round(avg(price),2) as average_price \n",
    "                        from df_renamed \n",
    "                        group by product_type \n",
    "                        order by total_revenue desc\"\"\"\n",
    "                        )\n",
    "\n",
    "top_revenue.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e84d6f0d-b63a-41cb-8351-b6cda9cdd5fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n| location|total_revenue|\n+---------+-------------+\n|Bangalore|    102601.72|\n|  Chennai|    119142.82|\n|   Mumbai|    137755.03|\n|  Kolkata|    137077.55|\n|    Delhi|      81027.7|\n+---------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Revenue analysis based on location\n",
    "df_renamed.createOrReplaceTempView(\"df_renamed\")\n",
    "revenue_by_location=spark.sql(\"\"\"\n",
    "                              select location, round(sum(revenue_generated),2) as total_revenue from df_renamed \n",
    "                              group by location\"\"\")\n",
    "revenue_by_location.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fafef1e-e7e8-4852-aa7a-15304d5b2af7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n|  sku|revenue|\n+-----+-------+\n|SKU51|9866.47|\n|SKU38|9692.32|\n|SKU31|9655.14|\n|SKU90|9592.63|\n| SKU2|9577.75|\n+-----+-------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "#Identifying top selling product on revenue \n",
    "\n",
    "df_renamed.createOrReplaceTempView(\"df_renamed\")\n",
    "top_revenue_by_product=spark.sql(\"\"\"\n",
    "                                 select sku,round(revenue_generated,2) as revenue from df_renamed\n",
    "                                 order by revenue_generated desc\"\"\")\n",
    "top_revenue_by_product.show(5)                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e5f91af-94bf-42b0-a4d8-8b4965fda659",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price and revenue_generated correlation is 0.0384\nprice and number_of_products_sold correlation is 0.0057\nrevenue_generated and number_of_products_sold correlation is -0.0016\n"
     ]
    }
   ],
   "source": [
    "# finding correlation between price and revenue | no of products sold and revenue\n",
    "from pyspark.sql.functions import corr\n",
    "\n",
    "new_df = df_renamed.select(\"price\",\"revenue_generated\",\"number_of_products_sold\")\n",
    "                                 \n",
    "for i in range(len(new_df.columns)):\n",
    "    for j in range(i+1, len(new_df.columns)):\n",
    "      col1=new_df.columns[i]\n",
    "      col2=new_df.columns[j]\n",
    "      correlation = round(new_df.stat.corr(col1,col2),4)\n",
    "      print(f\"{col1} and {col2} correlation is {correlation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee07d618-2b3c-45f9-bdc0-685a207baacc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Customer Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "365fd2b6-8b6d-40bc-bc21-d8c586664e74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------+\n|customer_demographics|total_revenue|\n+---------------------+-------------+\n|              Unknown|    173090.13|\n|               Female|    161514.49|\n|                 Male|    126634.39|\n|           Non-binary|     116365.8|\n+---------------------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_renamed.createOrReplaceTempView(\"df_renamed\")\n",
    "\n",
    "top_buying_demographic = spark.sql(\"\"\"\n",
    "                                   select customer_demographics,round(sum(revenue_generated),2) as total_revenue from df_renamed\n",
    "                                   group by customer_demographics\n",
    "                                   order by total_revenue desc\"\"\")\n",
    "top_buying_demographic.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9b84b4a-fb09-4d6b-a37f-4a641a5e1352",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+---------+--------+--------+\n|customer_demographics|cosmetics|haircare|skincare|\n+---------------------+---------+--------+--------+\n|               Female|     4012|     936|    7853|\n|              Unknown|     2834|    7563|    4814|\n|           Non-binary|     2607|    2820|    5153|\n|                 Male|     2304|    2292|    2911|\n+---------------------+---------+--------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr,sum\n",
    "\n",
    "# finding a relation between customer demographic and their purchases\n",
    "\n",
    "df_renamed.createOrReplaceTempView(\"df_renamed\")\n",
    "demographic_purchasing_pattern = df_renamed.groupBy(\"customer_demographics\").pivot(\"product_type\").sum(\"number_of_products_sold\")\n",
    "demographic_purchasing_pattern.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a459b55d-bbfb-4877-af33-37e799344d91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Product Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7e760b1-aa53-4a93-a019-ed94322331c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n|  sku| Profit|\n+-----+-------+\n| SKU2|9397.09|\n|SKU38|9337.48|\n|SKU67|9288.32|\n|SKU88|9268.84|\n|SKU51|9152.51|\n+-----+-------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,round,desc\n",
    "#Identify products with high and low profitability \n",
    "\n",
    "df_renamed.createOrReplaceTempView(\"df_renamed\")\n",
    "df_renamed.select(\"sku\",round((col(\"revenue_generated\")-col(\"shipping_costs\")-col(\"costs\")-col(\"manufacturing_costs\")),2).alias(\"Profit\")).orderBy(desc(\"profit\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c78ed92-b53a-47be-880b-94a96ff58b69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+\n|product_type|avg_defect_rate|\n+------------+---------------+\n|    skincare|           2.33|\n|   cosmetics|           1.92|\n|    haircare|           2.48|\n+------------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "# average defect rates by product type\n",
    "df_renamed.createOrReplaceTempView(\"df_renamed\")\n",
    "defect_rates_by_product_type = spark.sql(\"\"\"\n",
    "                                         select product_type,round(avg(defect_rates),2) as avg_defect_rate from df_renamed \n",
    "                                         group by product_type\"\"\")\n",
    "defect_rates_by_product_type.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3625a16-cad4-4cfb-a911-332f998c7e3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+\n|  sku|avg_defect_rate|\n+-----+---------------+\n|SKU42|           4.94|\n|SKU65|           4.91|\n| SKU1|           4.85|\n|SKU84|           4.84|\n|SKU50|           4.75|\n+-----+---------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# average defect rates by sku\n",
    "df_renamed.createOrReplaceTempView(\"df_renamed\")\n",
    "defect_rates_by_product_type = spark.sql(\"\"\"\n",
    "                                         select sku,round(avg(defect_rates),2) as avg_defect_rate from df_renamed \n",
    "                                         group by sku\n",
    "                                         order by avg_defect_rate desc\"\"\")\n",
    "defect_rates_by_product_type.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd10a2cf-89ca-4ecf-8825-15f3d1b7e5f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------+\n|shipping_carriers|avg_lead_time|\n+-----------------+-------------+\n|        Carrier A|        18.32|\n|        Carrier C|        17.14|\n|        Carrier B|        16.23|\n+-----------------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr,sum,avg,round,desc\n",
    "\n",
    "# average lead time by product type ( The lead time here refers to a time between order of the product to delivery of the product. in this dataset let's assume days)\n",
    "\n",
    "df_renamed.createOrReplaceTempView(\"df_renamed\")\n",
    "df_renamed.groupBy(\"shipping_carriers\").agg(round(avg(\"lead_time\"),2).alias(\"avg_lead_time\")).orderBy(desc(\"avg_lead_time\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62042305-a358-43d7-8b06-78571a134b64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n|shipping_carriers|avg_shipping_cost|\n+-----------------+-----------------+\n|        Carrier C|              5.6|\n|        Carrier A|             5.55|\n|        Carrier B|             5.51|\n+-----------------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr,sum,avg,round,desc\n",
    "\n",
    "# average shipping cost by product type\n",
    "\n",
    "df_renamed.createOrReplaceTempView(\"df_renamed\")\n",
    "df_renamed.groupBy(\"shipping_carriers\").agg(round(avg(\"shipping_costs\"),2).alias(\"avg_shipping_cost\")).orderBy(desc(\"avg_shipping_cost\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95529985-7c10-49f6-92b5-ba2fcb518513",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_renamed.write.option(\"header\",\"true\").mode(\"overwrite\").csv(\"/mnt/supplychain/transformed-data/SCdataset\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1424721447299287,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "supply_chain_transformation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}